{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 02: Atributos Categóricos e Valores Faltantes\n",
    "### Aluno: Alisson da Silva Vieira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas utilizadas\n",
    "- Numpy: É uma biblioteca fundamental para computação científica em Python, que fornece um objeto de matriz multidimensional, vários objetos derivados (como matrizes e matrizes mascaradas) e uma variedade de rotinas para operações rápidas em matrizes.\n",
    "- Pandas: É uma biblioteca que fornece estruturas de dados rápidas, flexíveis e expressivas projetadas para tornar o trabalho com dados \"relacionais\" ou \"rotulados\" fácil e intuitivo. Tem como objetivo ser o bloco de construção fundamental de alto nível para fazer análises de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente abrimos o arquivo .csv, e conseguimos analisar os primeiros 5 dados do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/agaricus_lepiota_small_c.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos analisar também as colunas. </br>\n",
    "De cara já verificamos que apenas a coluna 'stalk-root' possui valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E para uma melhor análise, conseguimos fazer uma breve análise estatística, agrupando nossos dados pela coluna 'class'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('class').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os dados da coluna 'stalk-root' possuem valores faltantes, irei tirar essa coluna do dataset. <br>\n",
    "Minha hipotese é de que como temos várias outras colunas, tirar a coluna 'stalk-root' pode não prejudir a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['stalk-root'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos perceber que todos os nossos dados possuem valores ordinais, então temos que realizar uma transformação para que os dados sejam categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [\n",
    "    ('v_class', OrdinalEncoder(categories=[['e', 'p']]), ['class']),\n",
    "    ('v_cap-shape', OrdinalEncoder(), ['cap-shape']),\n",
    "    ('v_cap-surface', OrdinalEncoder(), ['cap-surface']),\n",
    "    ('v_cap-color', OrdinalEncoder(), ['cap-color']),\n",
    "    ('v_bruises', OrdinalEncoder(categories=[['t', 'f']]), ['bruises']),\n",
    "    ('v_odor', OrdinalEncoder(), ['odor']),\n",
    "    ('v_gill-attachment', OrdinalEncoder(), ['gill-attachment']),\n",
    "    ('v_gill-spacing', OrdinalEncoder(categories=[['c', 'w', 'd']]), ['gill-spacing']),\n",
    "    ('v_gill-size', OrdinalEncoder(categories=[['b', 'n']]), ['gill-size']),\n",
    "    ('v_gill-color', OrdinalEncoder(), ['gill-color']),\n",
    "    ('v_stalk-shape', OrdinalEncoder(categories=[['e', 't']]), ['stalk-shape']),\n",
    "    # ('v_stalk-root', OrdinalEncoder(), ['stalk-root']),\n",
    "    ('v_stalk-surface-above-ring', OrdinalEncoder(), ['stalk-surface-above-ring']),\n",
    "    ('v_stalk-surface-below-ring', OrdinalEncoder(), ['stalk-surface-below-ring']),\n",
    "    ('v_stalk-color-above-ring', OrdinalEncoder(), ['stalk-color-above-ring']),\n",
    "    ('v_stalk-color-below-ring', OrdinalEncoder(), ['stalk-color-below-ring']),\n",
    "    ('v_veil-type', OrdinalEncoder(categories=[['p', 'u']]), ['veil-type']),\n",
    "    ('v_veil-color', OrdinalEncoder(), ['veil-color']),\n",
    "    ('v_ring-number', OrdinalEncoder(categories=[['n', 'o', 't']]), ['ring-number']),\n",
    "    ('v_ring-type', OrdinalEncoder(), ['ring-type']),\n",
    "    ('v_spore-print-color', OrdinalEncoder(), ['spore-print-color']),\n",
    "    ('v_population', OrdinalEncoder(), ['population']),\n",
    "    ('v_habitat', OrdinalEncoder(), ['habitat'])\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers=transformers)\n",
    "\n",
    "X_oe = ct.fit_transform(df)\n",
    "df_oe = pd.DataFrame(X_oe, columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse é o resultado depois da transfomração dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosneguimos observar melhor o tipo dos valores das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oe = df_oe.values\n",
    "y_oe = df_oe['class'].values\n",
    "\n",
    "df_oe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo se encontra as funções responsáveis pela classificação dos dados, usando o SVM e o KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ### Funções referente ao classificador KNN ####\n",
    "'''\n",
    "\n",
    "def validacaoCruzadaKnn(X, y, kVias = 10):\n",
    "\n",
    "    print('Iniciando a validação cruzada com o classificado KNN...')\n",
    "\n",
    "    # acuracias\n",
    "    acuracias = []\n",
    "\n",
    "    # usar o protocolo de validação cruzada estratificada\n",
    "    skf = StratifiedKFold(n_splits=kVias, shuffle=True, random_state=1)\n",
    "\n",
    "    pgb = tqdm(total=kVias, desc=\"Fold's avaliados\")\n",
    "\n",
    "    for idx_treino, idx_teste in skf.split(X, y):\n",
    "\n",
    "        # extrair as instâncias de treinamento de acordo com os índices fornecidos pelo skf.split\n",
    "        X_treino = X[idx_treino]\n",
    "        y_treino = y[idx_treino]\n",
    "        \n",
    "        # extrair as instâncias de teste de acordo com os índices fornecidos pelo skf.split\n",
    "        X_teste = X[idx_teste]\n",
    "        y_teste = y[idx_teste]\n",
    "\n",
    "        # separar as instâncias de treinamento entre treinamento e validação para a otimização do hiperparâmetro k\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, test_size=0.2, stratify=y_treino, shuffle=True, random_state=1)\n",
    "\n",
    "        params = {'n_neighbors' : range(1,30,2)}\n",
    "\n",
    "        # ss = StandardScaler()\n",
    "        # ss.fit(X_treino)\n",
    "        # X_treino = ss.transform(X_treino)\n",
    "        # X_teste = ss.transform(X_teste)\n",
    "        # X_val = ss.transform(X_val)\n",
    "\n",
    "        knn = GridSearchCV(KNeighborsClassifier(), params, cv=StratifiedKFold(n_splits=5))\n",
    "        knn.fit(np.vstack((X_treino, X_val)), [*y_treino, *y_val])\n",
    "        \n",
    "        pred = knn.predict(X_teste)\n",
    "\n",
    "        print('f1-socre: ', f1_score(y_teste, pred), '\\nOutro: ', accuracy_score(y_teste, pred))\n",
    "\n",
    "        # calcular a acurácia no conjunto de testes desta iteração e salvar na lista.\n",
    "        acuracias.append(accuracy_score(y_teste, pred))\n",
    "\n",
    "        pgb.update(1)\n",
    "        \n",
    "    pgb.close()\n",
    "    \n",
    "    return acuracias\n",
    "\n",
    "'''\n",
    "    ### Funções referente ao classificador SVM ####\n",
    "'''\n",
    "\n",
    "def validacaoCruzadaSvm(X, y, cv_splits, Cs=[1], gammas=['scale']):\n",
    "\n",
    "    print('Iniciando a validação cruzada com o classificador SVM...')\n",
    "\n",
    "    parameters = [{\n",
    "        'gamma': gammas,\n",
    "        'C': Cs,\n",
    "        'kernel': ['rbf']\n",
    "    }]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    acuracias = []\n",
    "    \n",
    "    pgb = tqdm(total=cv_splits, desc=\"Fold's avaliados\")\n",
    "    \n",
    "    for treino_idx, teste_idx in skf.split(X, y):\n",
    "\n",
    "        X_treino = X[treino_idx]\n",
    "        y_treino = y[treino_idx]\n",
    "\n",
    "        X_teste = X[teste_idx]\n",
    "        y_teste = y[teste_idx]\n",
    "\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, stratify=y_treino, test_size=0.2, random_state=1)\n",
    "\n",
    "        # ss = StandardScaler()\n",
    "        # ss.fit(X_treino)\n",
    "        # X_treino = ss.transform(X_treino)\n",
    "        # X_teste = ss.transform(X_teste)\n",
    "        # X_val = ss.transform(X_val)\n",
    "\n",
    "        svm = GridSearchCV(SVC(), parameters, cv=StratifiedKFold(n_splits=5))\n",
    "        svm.fit(np.vstack((X_treino, X_val)), [*y_treino, *y_val])\n",
    "        \n",
    "        pred = svm.predict(X_teste)\n",
    "\n",
    "        print('f1-socre: ', f1_score(y_teste, pred), '\\nOutro: ', accuracy_score(y_teste, pred))\n",
    "\n",
    "        acuracias.append(accuracy_score(y_teste, pred))\n",
    "\n",
    "        pgb.update(1)\n",
    "        \n",
    "    pgb.close()\n",
    "    \n",
    "    return acuracias\n",
    "\n",
    "'''\n",
    "    ### Funções auxiliares ####\n",
    "'''\n",
    "\n",
    "def showResult(acc, legend):\n",
    "    print('Resultado ', legend, '\\n    >> Acc mínima: ', round(min(acc), 3), '%\\n    >> Acc máxima: ', round(max(acc), 3), '%')\n",
    "    print('    >> Média: ', round(np.mean(acc), 3), '\\n    >> Desvio padrão: ', round(np.std(acc), 3), '\\n')\n",
    "\n",
    "    return np.mean(acc), np.std(acc)\n",
    "\n",
    "def hipoteseNula(media1, std1, values1, media2, std2, values2, alpha=0.05):\n",
    "    pvalor = ttest_ind_from_stats(media1, std1, len(values1), media2, std2, len(values2))[1]\n",
    "    \n",
    "    return pvalor <= alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accKnn = validacaoCruzadaKnn(X_oe, y_oe)\n",
    "accSvm = validacaoCruzadaSvm(X_oe, y_oe, 10, Cs=[1, 10, 100, 1000], gammas=['scale', 'auto', 2e-2, 2e-3, 2e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaKnn, stdKnn = showResult(accKnn, 'knn')\n",
    "mediaSvm, stdSvm = showResult(accSvm, 'svm')\n",
    "\n",
    "hpnula = hipoteseNula(mediaKnn, stdKnn, accKnn, mediaSvm, stdSvm, accSvm)\n",
    "\n",
    "if hpnula:\n",
    "    if mediaKnn > mediaSvm:\n",
    "        classif = ' knn '\n",
    "    else:\n",
    "        classif = ' svm '\n",
    "\n",
    "    text = 'verdadeira, podemos dizer que o' + classif + 'obteve um resultado melhor.'\n",
    "else:\n",
    "    text = 'falsa, não conseguimos afirmar que os dois resultados são estatisticamente diferentes.'\n",
    "\n",
    "print('Hipotese nula:', text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a01cbe3509f40fe8fbb70f6e35a414a4aeac5b623ad71bdf179810de598dc153"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
